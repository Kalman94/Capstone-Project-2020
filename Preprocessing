# -*- coding: utf-8 -*-
"""
Created on Sat Jan 25 03:33:58 2020

@author: 30694
"""

# -*- coding: utf-8 -*-
"""
Created on Thu Jan 23 12:59:05 2020

@author: 30694
"""

# -*- coding: utf-8 -*-
"""
Created on Fri Dec 20 23:05:46 2019

@author: teo
"""

import cv2
import numpy as np
from matplotlib import pyplot as plt
import scipy
from scipy.spatial.distance import euclidean
import glob
import pandas as pd
import os


def largestCC (img):
    img = img.astype(np.uint8)
    nlabels, labels, stats, centroids = cv2.connectedComponentsWithStats(img)
    # stats[0] is the background
    max_component = 1
    for i in range (2,len(stats)):
        if stats[i][4] > stats[max_component][4]:
            max_component = i
    for i in range (0,len(labels)):
        for j in range (0,len(labels[i])):
            if labels[i][j] != max_component:
                labels[i][j] = 0
    for i in range (0,len(labels)):
        for j in range (0,len(labels[i])):
            if labels[i][j] == 0:
                img[i][j] = 0
            else:
                img[i][j] = 255
    return img


def getBondLength(centroids):
    '''This function gets as input the centroids that are calculated from connected components with stats
    and returns the median value of the distances (bond lenght) between them
    '''
    distances = np.array(scipy.spatial.distance.cdist(centroids, centroids, 'euclidean'))
    forAverage = []
    for i in range (len(distances)):
        distances[i] = np.sort(distances[i])
        forAverage.append(distances[i][1])
    return np.median(forAverage)

Images = pd.DataFrame()

#Loop through every Image
for image_path in glob.glob("C:\\Users\\30694\\Documents\\GitHub\\DataFolder\\*.png"):
    #We read the image in grayscale
    image_gray = cv2.imread(image_path,0)

    #We read the original image
    image_rgb=cv2.imread(image_path)

    #We convert the grayscale image to np.float type for "Harris"
    forHarrisGrayImage=np.float32(image_gray)

    #We perform Harris corner detection with a window size of 7. The outcome is an inverted image with the detected corners
    doneHarris = cv2.cornerHarris(forHarrisGrayImage,7,3,0.04)

    #We create a copy of our original image
    copyImage1_rgb = image_rgb.copy()

    #We apply to the copy of the original image to see our outcome. We get the original image with red coloured dots on the conrners.
    copyImage1_rgb[doneHarris>0.01*doneHarris.max()]=[0,0,255]

    #We create a white coloured image of the same size as the original(white canvas)
    blankImage1 = 255*np.ones((copyImage1_rgb.shape[0], copyImage1_rgb.shape[1], 3))

    #We apply the white canvas to everything in our image except the red coloured corners and in the end we get a white background with the red coloured corners
    blankImage1[doneHarris>0.01*doneHarris.max()]=[0,0,255]

    #We have too many corners. We want to find the biggest object and find features for this object. So we need to convert the image on inverted binary and perform connected components method
    ret,thresholdedImage = cv2.threshold(forHarrisGrayImage,200,255,cv2.THRESH_BINARY_INV)

    #We create a white coloured image of the same size as the original(white canvas)
    blankImage1 = 255*np.ones((copyImage1_rgb.shape[0], copyImage1_rgb.shape[1], 3))

    #We call the "largestCC" function that performs connected components
    largestComponent = largestCC(thresholdedImage)

    #We perfrom binary inversion so our largest object is again black and the background is white
    ret,largestComponent = cv2.threshold(largestComponent,200,255,cv2.THRESH_BINARY_INV)

    #At this step we perforom bluring (twice) to our image in order to get more precise corners (features)
    largestComponent_blur = cv2.blur(largestComponent,(3,3))
    largestComponent_blur1 = cv2.blur(largestComponent_blur,(3,3))

    #We convert the image to np.float type for "Harris"
    Larg_CC_Harris = np.float32(largestComponent_blur1)

    #We perform Harris corner detection with a window size of 7. The outcome is an inverted image with the detected corners
    doneHarris_CC = cv2.cornerHarris(Larg_CC_Harris,7,3,0.04)

    #We create a white coloured image of the same size as the original(white canvas)
    blankImage1 = 255*np.ones((copyImage1_rgb.shape[0], copyImage1_rgb.shape[1], 3))

    # forHarrisGrayImage1 = np.float32(largestComponent_blur1)
    # After testing we concluded that we get the best results for free parameter (k= 0.01)
    doneHarris1_CC = cv2.cornerHarris(Larg_CC_Harris,7,3,0.01)
    copyImage2_rgb = image_rgb.copy()

    # Then as a second step we apply Harris to the previous for k= 0.25 and we apply the results to the copy of the initial image
    copyImage2_rgb[doneHarris1_CC>0.25*doneHarris1_CC.max()]=[0,0,255]

    #We create a white coloured image of the same size as the original(white canvas)
    blankImage1 = 255*np.ones((copyImage1_rgb.shape[0], copyImage1_rgb.shape[1], 3))

    #We add the features to the blank canva. This way we have isolated the features
    blankImage1[doneHarris1_CC>0.25*doneHarris1_CC.max()]=[0,0,255]

    #We change the format of the pixels from np.float to np.uint so we can work with open-cv
    blankImage1 = np.uint8(blankImage1)

    # We convert our image to grayscale so we can threshold and get an inverted binary version of the image on which we will perform connected
    # components analysis
    blankImage1 = cv2.cvtColor(blankImage1, cv2.COLOR_BGR2GRAY)
    ret,blankImage1 = cv2.threshold(blankImage1,127,255,cv2.THRESH_BINARY_INV)
    nlabels, labels, stats, centroids = cv2.connectedComponentsWithStats(blankImage1)

    # We get the median bond in respect to distances between centroids. So we have one median for each picture
    centroid_medianvalue=getBondLength(centroids)
   
    # We store the values to a dataframe so we can later get the max lenght bond between all the image from which
    # we will calculate the ratios for rescaling
    Images = Images.append({'ImageName':image_path,'Centroids':centroid_medianvalue,'nlabels':nlabels}, ignore_index=True)


highiestBond_Length=Images['Centroids'].max()
Images['ratio']=highiestBond_Length/Images['Centroids']
#my_list = Images['ratio'].tolist()
#newImages=[]
#rawData=[]
# We rescale the images and pass them to a new folder. This will be the dataset which we will use to extract features
for i in Images.index:
    image = cv2.imread(Images['ImageName'][i])
    image_copy=image.copy()
    temp = cv2.resize(image_copy, (0,0), fx=Images['ratio'][i], fy=Images['ratio'][i])
    blankImage = 255*np.ones((1100, 1100, 3))
    blankImage = np.uint8(blankImage)
    blankImage[0:temp.shape[0],0:temp.shape[1]] = temp
    s = 'C:\\Users\\30694\\Documents\\GitHub\\DataFolder\\new_images\\'+ str(os.path.basename(Images['ImageName'][i]))
#    newImages.append(s)
#    rawData.append(blankImage)
#    Images2= Images2.append({'newImages':s[i],'rawData':blankImage[i]}, ignore_index=True)
    cv2.imwrite(s, blankImage)
#Images2 = pd.DataFrame({'col':newImages,'col2':rawData})
#bigdata = pd.concat([Images, Images2], axis=1)
#bigdata = Images.append(Images2, ignore_index=True)
#Images.to_csv('ImagesDataFrame.csv', sep=',', index=False)